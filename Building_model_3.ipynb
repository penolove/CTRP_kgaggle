{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create Sparse Matrix\n",
    "\n",
    "fail due to >pd.get_dummies is extremely unefficientcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "X_train = pd.read_csv(\"data/train.csv\")\n",
    "X_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=X_test.columns.values[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling col :  C1\n",
      "handling col :  banner_pos\n",
      "handling col :  site_id\n",
      "handling col :  site_domain\n",
      "handling col :  site_category\n",
      "handling col :  app_id\n",
      "handling col :  app_domain\n",
      "handling col :  app_category\n",
      "handling col :  device_id\n",
      "handling col :  device_ip\n",
      "handling col :  device_model\n",
      "handling col :  device_type\n",
      "handling col :  device_conn_type\n",
      "handling col :  C14\n",
      "handling col :  C15\n",
      "handling col :  C16\n",
      "handling col :  C17\n",
      "handling col :  C18\n",
      "handling col :  C19\n",
      "handling col :  C20\n",
      "handling col :  C21\n"
     ]
    }
   ],
   "source": [
    "features = X_test.columns.values[2:]\n",
    "for column in features:\n",
    "    print(\"handling col : \",column )\n",
    "    categories = pd.concat([X_train[column],X_test[column]]).unique()\n",
    "    X_train[column] = X_train[column].astype('category', categories=categories)\n",
    "    X_test[column] = X_test[column].astype('category', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.to_pickle(\"Train_cate\")\n",
    "X_test.to_pickle(\"Test_cate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=pd.read_pickle(\"Train_cate\")\n",
    "X_test=pd.read_pickle(\"Test_cate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into 5 folds\n",
    "import numpy as np\n",
    "def n_fold_split(df, k, seed=5566):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df)\n",
    "    fold_size = int(m/k)\n",
    "    fold_list = []\n",
    "    for i in range(k):\n",
    "        if i!=(k-1):\n",
    "            target_range=range(i*fold_size,(i+1)*fold_size)\n",
    "        else:\n",
    "            target_range=range(i*fold_size,m)\n",
    "        current_df = df.iloc[perm[target_range]]\n",
    "        fold_list.append(current_df)\n",
    "    return fold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchsize: 8085793\n",
      "batchsize: 8085793\n",
      "batchsize: 8085793\n",
      "batchsize: 8085793\n",
      "batchsize: 8085795\n"
     ]
    }
   ],
   "source": [
    "X_train_list = n_fold_split(X_train,5)\n",
    "for i in X_train_list:\n",
    "    print(\"batchsize:\",len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=X_test.columns.values[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C1', 'banner_pos', 'site_id', 'site_domain', 'site_category',\n",
       "       'app_id', 'app_domain', 'app_category', 'device_id', 'device_ip',\n",
       "       'device_model', 'device_type', 'device_conn_type', 'C14', 'C15',\n",
       "       'C16', 'C17', 'C18', 'C19', 'C20', 'C21'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.get_dummies(X_test, columns=features, sparse=True)\n",
    "# extremely slowly and run-out memory (even with only Test dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build with handly csr matrix\n",
    "what we want -> a very large matrix with all category variable were translated to dummy\n",
    "\n",
    "and sloving with logistic regression\n",
    "\n",
    "### 1. load df from FF ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "X_train = pd.read_pickle('train_df_hash')\n",
    "X_test = pd.read_pickle('test_df_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column2handle = X_train.columns.values[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. split to 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into 5 folds\n",
    "import numpy as np\n",
    "def n_fold_split(df, k, seed=5566):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df)\n",
    "    fold_size = int(m/k)\n",
    "    fold_list = []\n",
    "    for i in range(k):\n",
    "        if i!=(k-1):\n",
    "            target_range=range(i*fold_size,(i+1)*fold_size)\n",
    "        else:\n",
    "            target_range=range(i*fold_size,m)\n",
    "        current_df = df.iloc[perm[target_range]]\n",
    "        fold_list.append(current_df)\n",
    "    return fold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchsize: 8085793\n",
      "batchsize: 8085793\n",
      "batchsize: 8085793\n",
      "batchsize: 8085793\n",
      "batchsize: 8085795\n"
     ]
    }
   ],
   "source": [
    "X_train_list = n_fold_split(X_train,5)\n",
    "for i in X_train_list:\n",
    "    print(\"batchsize:\",len(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. filling hash values into dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size :  8085793 \n",
      "test set size :  4577464\n"
     ]
    }
   ],
   "source": [
    "print(\"training set size : \",len(X_train_list[0]), \"\\ntest set size : \",len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_dok = dok_matrix((8085793, 10269200), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1_hash\n",
      "banner_pos_hash\n",
      "site_id_hash\n",
      "site_domain_hash\n",
      "site_category_hash\n",
      "app_id_hash\n",
      "app_domain_hash\n",
      "app_category_hash\n",
      "device_id_hash\n",
      "device_ip_hash\n",
      "device_model_hash\n",
      "device_type_hash\n",
      "device_conn_type_hash\n",
      "C14_hash\n",
      "C15_hash\n",
      "C16_hash\n",
      "C17_hash\n",
      "C18_hash\n",
      "C19_hash\n",
      "C20_hash\n",
      "C21_hash\n",
      "weekday_hash\n",
      "hour__hash\n",
      "CPU times: user 1min 12s, sys: 7.68 s, total: 1min 20s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in column2handle:\n",
    "    print(i)\n",
    "    target = X_train_list[0][i]\n",
    "    X_train_dok[range(8085793),target.values]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dok = X_train_dok.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7421"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save csr_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def save_sparse_csr(filename, array):\n",
    "    # note that .npz extension is added automatically\n",
    "    np.savez(filename, data=array.data, indices=array.indices,\n",
    "             indptr=array.indptr, shape=array.shape)\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    # here we need to add .npz extension manually\n",
    "    loader = np.load(filename + '.npz')\n",
    "    return csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                      shape=loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_sparse_csr('X_train_csr_1', X_train_dok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for j in range(5):\n",
    "    X_train_dok = dok_matrix(( len(X_train_list[j]), 10269200), dtype=np.bool)\n",
    "    gc.collect()\n",
    "    for i in column2handle:\n",
    "        print(i)\n",
    "        target = X_train_list[j][i]\n",
    "        X_train_dok[range(len(X_train_list[j])),target.values]=1\n",
    "        \n",
    "    X_train_dok = X_train_dok.tocsr()\n",
    "    save_sparse_csr('X_train_csr_'+str(j), X_train_dok)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(4, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SGDClassifier(alpha=.0001, n_iter=50,penalty=penalty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
